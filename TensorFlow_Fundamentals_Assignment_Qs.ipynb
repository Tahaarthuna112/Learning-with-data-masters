{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZIUOe6uz8LGvbu5DfDyuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tahaarthuna112/Learning-with-data-masters/blob/main/TensorFlow_Fundamentals_Assignment_Qs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKQZ8ikhuMUz"
      },
      "outputs": [],
      "source": [
        "Part 1: Theoretical Queltionk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1) What are the different data structures used in Tensorflow?. Give some examples?"
      ],
      "metadata": {
        "id": "4mdc7B4qujpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "In TensorFlow, various data structures are used to handle and manipulate data during the machine learning and deep learning workflow. These data structures are designed to efficiently represent, store, and process data, especially for large-scale computations like those required in deep learning models. Here are the key data structures used in TensorFlow:\n",
        "\n",
        "### 1. **Tensors**:\n",
        "   - **Tensors** are the core data structure in TensorFlow. They represent multi-dimensional arrays of numerical data and are the basic building blocks for computations in TensorFlow. A tensor can have any number of dimensions (0D, 1D, 2D, etc.), also known as its **rank**.\n",
        "   - TensorFlow operations (or \"ops\") are applied to tensors, allowing for efficient computation on CPU or GPU.\n",
        "\n",
        "   **Examples**:\n",
        "   - **0D Tensor** (scalar): A single number.\n",
        "     Example: `tf.constant(5)`\n",
        "   - **1D Tensor** (vector): A one-dimensional array of numbers.\n",
        "     Example: `tf.constant([1.0, 2.0, 3.0])`\n",
        "   - **2D Tensor** (matrix): A two-dimensional array (like a table of numbers).\n",
        "     Example: `tf.constant([[1, 2], [3, 4]])`\n",
        "   - **3D Tensor**: A tensor with three dimensions, often used for image data.\n",
        "     Example: `tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])`\n",
        "\n",
        "### 2. **Variables**:\n",
        "   - **Variables** are special tensors in TensorFlow that are used to store and update model parameters during training. Unlike constants, variables are mutable, meaning their values can be changed during the execution of a model.\n",
        "   - Variables are typically used to store the weights and biases of a model and can be updated through backpropagation.\n",
        "\n",
        "   **Examples**:\n",
        "   - A trainable weight matrix:\n",
        "     ```python\n",
        "     weight = tf.Variable(tf.random.normal([5, 5], stddev=0.1))\n",
        "     ```\n",
        "\n",
        "### 3. **Sparse Tensors**:\n",
        "   - **Sparse tensors** represent tensors that contain mostly zero values, which helps optimize memory usage when working with large datasets that have a sparse representation. Instead of storing every element, sparse tensors store only the non-zero values and their corresponding indices.\n",
        "\n",
        "   **Examples**:\n",
        "   ```python\n",
        "   sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
        "   ```\n",
        "\n",
        "### 4. **Ragged Tensors**:\n",
        "   - **Ragged tensors** are tensors with variable-length dimensions. They are used to handle data that doesn't fit into a regular grid, such as sequences of varying lengths (e.g., sentences in natural language processing or irregularly shaped images).\n",
        "\n",
        "   **Examples**:\n",
        "   - A batch of sentences with different lengths:\n",
        "     ```python\n",
        "     ragged_tensor = tf.ragged.constant([[1, 2, 3], [4, 5], [6]])\n",
        "     ```\n",
        "\n",
        "### 5. **TensorArray**:\n",
        "   - **TensorArray** is a dynamic array of tensors used in cases where the size of the array is not known in advance. It is useful in constructing loops and dynamic computation graphs in TensorFlow.\n",
        "\n",
        "   **Examples**:\n",
        "   - Creating a dynamic array to store intermediate results in a loop:\n",
        "     ```python\n",
        "     array = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
        "     ```\n",
        "\n",
        "### 6. **Dataset**:\n",
        "   - The **Dataset** API provides a flexible way to create and work with input data pipelines in TensorFlow. It is used to load and process large datasets in an efficient, scalable manner. Datasets can be created from data in memory (e.g., numpy arrays) or from files (e.g., images or text data).\n",
        "\n",
        "   **Examples**:\n",
        "   - Creating a dataset from a list of tensors:\n",
        "     ```python\n",
        "     dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5])\n",
        "     ```\n",
        "\n",
        "   - Creating a dataset from a CSV file:\n",
        "     ```python\n",
        "     dataset = tf.data.experimental.make_csv_dataset(file_pattern='data.csv', batch_size=32)\n",
        "     ```\n",
        "\n",
        "### 7. **Queues** (Deprecated in TensorFlow 2.x):\n",
        "   - **Queues** were used in TensorFlow 1.x to manage input pipelines for batch processing. They were useful for prefetching and organizing data during training. However, in TensorFlow 2.x, queues have largely been replaced by the `tf.data` API.\n",
        "\n",
        "   **Examples** (TensorFlow 1.x):\n",
        "   ```python\n",
        "   queue = tf.queue.FIFOQueue(capacity=10, dtypes=tf.float32)\n",
        "   ```\n",
        "\n",
        "### 8. **Lookup Tables**:\n",
        "   - **Lookup tables** are used to map data from one domain to another, such as mapping words to indices in natural language processing tasks. They are often used to handle categorical data or embeddings in deep learning models.\n",
        "\n",
        "   **Examples**:\n",
        "   - Creating a lookup table for string to index mapping:\n",
        "     ```python\n",
        "     table = tf.lookup.StaticHashTable(\n",
        "         initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "             keys=tf.constant([\"apple\", \"banana\"]),\n",
        "             values=tf.constant([0, 1])\n",
        "         ),\n",
        "         default_value=-1\n",
        "     )\n",
        "     ```\n",
        "\n",
        "### Summary:\n",
        "\n",
        "- **Tensors**: Core data structure, representing n-dimensional arrays.\n",
        "- **Variables**: Mutable tensors used to store model parameters.\n",
        "- **Sparse Tensors**: Efficient representation of tensors with mostly zero values.\n",
        "- **Ragged Tensors**: Handle data with variable-length dimensions.\n",
        "- **TensorArray**: Dynamic array of tensors, useful in loops.\n",
        "- **Dataset**: Efficient pipeline for loading and processing large datasets.\n",
        "- **Lookup Tables**: Map data from one domain to another, useful for categorical data.\n",
        "\n",
        "These data structures provide flexibility and efficiency in working with various types of data in TensorFlow, making it easier to build and train machine learning and deep learning models."
      ],
      "metadata": {
        "id": "u6iEvtZwu5-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2) How does the TensorFlow constant differ from a TensorFlow variable? Explain with an example?"
      ],
      "metadata": {
        "id": "T9qkYtdNu9Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "In TensorFlow, both **constants** and **variables** are used to store data, but they have key differences in terms of mutability and their roles in model training.\n",
        "\n",
        "### 1. **TensorFlow Constant (`tf.constant`)**:\n",
        "   - **Immutability**: A **constant** in TensorFlow is immutable, meaning that once it is created, its value cannot be changed. Constants are typically used for fixed values that do not need to be updated during the model's lifecycle, such as static hyperparameters or input data that will remain the same.\n",
        "   - **Use Case**: Constants are useful for scenarios where the data should remain unchanged, like the size of the input layer, or for passing values that are not modified during backpropagation in neural networks.\n",
        "\n",
        "   **Example**:\n",
        "   ```python\n",
        "   import tensorflow as tf\n",
        "\n",
        "   # Define a constant\n",
        "   const_tensor = tf.constant([1, 2, 3, 4], dtype=tf.int32)\n",
        "\n",
        "   print(\"Constant Tensor:\", const_tensor)\n",
        "   ```\n",
        "   Output:\n",
        "   ```\n",
        "   Constant Tensor: tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
        "   ```\n",
        "   In this example, `const_tensor` holds a fixed array of integers, and its values cannot be modified after initialization.\n",
        "\n",
        "### 2. **TensorFlow Variable (`tf.Variable`)**:\n",
        "   - **Mutability**: A **variable** in TensorFlow is mutable, meaning its value can be changed during the execution of a model. Variables are primarily used for storing model parameters (like weights and biases) that are updated during the training process through backpropagation.\n",
        "   - **Use Case**: Variables are critical in machine learning and deep learning models, where parameters need to be updated iteratively during training.\n",
        "\n",
        "   **Example**:\n",
        "   ```python\n",
        "   import tensorflow as tf\n",
        "\n",
        "   # Define a variable\n",
        "   var_tensor = tf.Variable([1, 2, 3, 4], dtype=tf.int32)\n",
        "\n",
        "   # Modify the variable's value\n",
        "   var_tensor.assign([5, 6, 7, 8])\n",
        "\n",
        "   print(\"Variable Tensor:\", var_tensor)\n",
        "   ```\n",
        "   Output:\n",
        "   ```\n",
        "   Variable Tensor: <tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([5, 6, 7, 8], dtype=int32)>\n",
        "   ```\n",
        "   In this example, `var_tensor` initially holds the array `[1, 2, 3, 4]`, but its values are modified using the `assign()` method. This mutability is crucial during training, where model parameters are updated after each training step.\n",
        "\n",
        "### Key Differences Between `tf.constant` and `tf.Variable`:\n",
        "| Aspect              | `tf.constant`                          | `tf.Variable`                             |\n",
        "|---------------------|----------------------------------------|-------------------------------------------|\n",
        "| **Mutability**       | Immutable (values can't be changed)    | Mutable (values can be updated)           |\n",
        "| **Typical Use**      | Fixed inputs like hyperparameters      | Model parameters like weights and biases  |\n",
        "| **Backpropagation**  | Not trainable (unchanged during training) | Trainable (updated during backpropagation)|\n",
        "| **Memory Management**| Memory allocated once                 | Memory updated as values change           |\n",
        "\n",
        "### Use Case in Model Training:\n",
        "- **Constants** are typically used for hyperparameters or fixed inputs (e.g., a constant learning rate).\n",
        "- **Variables** are used to store model weights, which are updated as the training process optimizes the model to minimize the loss function.\n",
        "\n",
        "### Example in a Simple Neural Network:\n",
        "In a neural network, the **weights** and **biases** are initialized as **variables** because they are adjusted with each training iteration. On the other hand, something like the **learning rate** or the structure of the network may be stored as a **constant**, as it remains the same throughout the training process.\n",
        "\n",
        "```python\n",
        "# Defining weights as a variable (trainable)\n",
        "weights = tf.Variable(tf.random.normal([2, 2]), name=\"weights\")\n",
        "\n",
        "# Defining learning rate as a constant (non-trainable)\n",
        "learning_rate = tf.constant(0.01, dtype=tf.float32)\n",
        "```\n",
        "\n",
        "In summary, **constants** are used for fixed values, while **variables** store parameters that need to be updated during model training. Understanding their distinction is essential for building efficient models in TensorFlow."
      ],
      "metadata": {
        "id": "Ud1SAbuOvKv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3) Describe the process of matrix addition, multiplication, and elementDwise operations in TensorFlow?"
      ],
      "metadata": {
        "id": "Bktt-r4nvM9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "In TensorFlow, matrix operations such as addition, multiplication, and element-wise operations are fundamental for constructing and training machine learning and deep learning models. Here’s a detailed description of each operation along with examples.\n",
        "\n",
        "### 1. **Matrix Addition**\n",
        "\n",
        "Matrix addition involves adding two matrices of the same dimensions by adding their corresponding elements. The result is a new matrix of the same size.\n",
        "\n",
        "**Mathematical Definition**:\n",
        "If \\( A \\) and \\( B \\) are two matrices of the same shape, their sum \\( C \\) is defined as:\n",
        "\\[\n",
        "C_{ij} = A_{ij} + B_{ij}\n",
        "\\]\n",
        "\n",
        "**TensorFlow Example**:\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define two matrices\n",
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Perform matrix addition\n",
        "C = tf.add(A, B)\n",
        "\n",
        "print(\"Matrix A:\")\n",
        "print(A.numpy())\n",
        "print(\"Matrix B:\")\n",
        "print(B.numpy())\n",
        "print(\"Matrix C (A + B):\")\n",
        "print(C.numpy())\n",
        "```\n",
        "\n",
        "**Output**:\n",
        "```\n",
        "Matrix A:\n",
        "[[1 2]\n",
        " [3 4]]\n",
        "Matrix B:\n",
        "[[5 6]\n",
        " [7 8]]\n",
        "Matrix C (A + B):\n",
        "[[ 6  8]\n",
        " [10 12]]\n",
        "```\n",
        "\n",
        "### 2. **Matrix Multiplication**\n",
        "\n",
        "Matrix multiplication involves multiplying two matrices, where the number of columns in the first matrix must equal the number of rows in the second matrix. The resulting matrix has the number of rows of the first matrix and the number of columns of the second matrix.\n",
        "\n",
        "**Mathematical Definition**:\n",
        "If \\( A \\) is an \\( m \\times n \\) matrix and \\( B \\) is an \\( n \\times p \\) matrix, the product \\( C \\) is given by:\n",
        "\\[\n",
        "C_{ij} = \\sum_{k=1}^{n} A_{ik} \\cdot B_{kj}\n",
        "\\]\n",
        "\n",
        "**TensorFlow Example**:\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define two matrices\n",
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Perform matrix multiplication\n",
        "C = tf.matmul(A, B)\n",
        "\n",
        "print(\"Matrix A:\")\n",
        "print(A.numpy())\n",
        "print(\"Matrix B:\")\n",
        "print(B.numpy())\n",
        "print(\"Matrix C (A * B):\")\n",
        "print(C.numpy())\n",
        "```\n",
        "\n",
        "**Output**:\n",
        "```\n",
        "Matrix A:\n",
        "[[1 2]\n",
        " [3 4]]\n",
        "Matrix B:\n",
        "[[5 6]\n",
        " [7 8]]\n",
        "Matrix C (A * B):\n",
        "[[19 22]\n",
        " [43 50]]\n",
        "```\n",
        "\n",
        "### 3. **Element-wise Operations**\n",
        "\n",
        "Element-wise operations perform operations on corresponding elements of two tensors (matrices or arrays) of the same shape. This includes addition, multiplication, and other arithmetic operations.\n",
        "\n",
        "**Mathematical Definition**:\n",
        "If \\( A \\) and \\( B \\) are two matrices of the same shape, their element-wise product \\( C \\) is defined as:\n",
        "\\[\n",
        "C_{ij} = A_{ij} \\cdot B_{ij}\n",
        "\\]\n",
        "\n",
        "**TensorFlow Example for Element-wise Operations**:\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define two matrices\n",
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Element-wise addition\n",
        "C_add = tf.add(A, B)\n",
        "\n",
        "# Element-wise multiplication\n",
        "C_mul = tf.multiply(A, B)\n",
        "\n",
        "print(\"Matrix A:\")\n",
        "print(A.numpy())\n",
        "print(\"Matrix B:\")\n",
        "print(B.numpy())\n",
        "print(\"Element-wise Addition (A + B):\")\n",
        "print(C_add.numpy())\n",
        "print(\"Element-wise Multiplication (A * B):\")\n",
        "print(C_mul.numpy())\n",
        "```\n",
        "\n",
        "**Output**:\n",
        "```\n",
        "Matrix A:\n",
        "[[1 2]\n",
        " [3 4]]\n",
        "Matrix B:\n",
        "[[5 6]\n",
        " [7 8]]\n",
        "Element-wise Addition (A + B):\n",
        "[[ 6  8]\n",
        " [10 12]]\n",
        "Element-wise Multiplication (A * B):\n",
        "[[ 5 12]\n",
        " [21 32]]\n",
        "```\n",
        "\n",
        "### Summary of Operations\n",
        "\n",
        "- **Matrix Addition**: Adds corresponding elements of two matrices of the same shape.\n",
        "- **Matrix Multiplication**: Multiplies two matrices where the number of columns in the first matrix matches the number of rows in the second matrix.\n",
        "- **Element-wise Operations**: Perform operations on corresponding elements of two tensors of the same shape, including addition, multiplication, and other arithmetic functions.\n",
        "\n",
        "These operations are fundamental in TensorFlow and are extensively used in building neural networks, where matrix and tensor manipulations are commonplace."
      ],
      "metadata": {
        "id": "C1KRYjQkvYok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Part 2: Practical Implementation\n",
        "\n",
        "Talk 1: Creating and Manipulating Matricek"
      ],
      "metadata": {
        "id": "p7EaIzqOvbZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1) Create a normal matrix A with dimensions ²x², using TensorFlow's random_normal function. Display the\n",
        "values of matrix A"
      ],
      "metadata": {
        "id": "C_qh1ySkvfeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a 3x3 matrix with random values from a normal distribution\n",
        "A = tf.random.normal(shape=(3, 3))\n",
        "\n",
        "# Display the value of matrix A\n",
        "print(\"Matrix A:\")\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb2quvdivjmC",
        "outputId": "e3f2fb98-963a-48ce-a4ce-7c25dc6ee84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "tf.Tensor(\n",
            "[[-0.10257177  0.63083196 -0.45404872]\n",
            " [-1.3704439  -0.30089492  1.4100798 ]\n",
            " [ 0.49787438 -0.5419311   1.0201961 ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2. Create a Gaussian Matrix B with dimension 4X4, using truncated_normal function. Display the values of Matrix B\n",
        "---"
      ],
      "metadata": {
        "id": "cV5grppHvpEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the dimensions of the matrix\n",
        "matrix_shape = (4, 4)\n",
        "\n",
        "# Generate a Gaussian matrix using truncated normal distribution\n",
        "mean = 0\n",
        "stddev = 1\n",
        "B = tf.random.truncated_normal(shape=matrix_shape, mean=mean, stddev=stddev)\n",
        "\n",
        "# Display the generated matrix\n",
        "print(\"Matrix B:\")\n",
        "print(B.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHke2WSov0Zh",
        "outputId": "bee4a195-02e8-4bca-b34c-ed208cfa31ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix B:\n",
            "[[-0.2085315  -0.16574441 -0.82045406 -1.0745512 ]\n",
            " [ 0.13144015 -1.3797266   1.1197685   0.6782506 ]\n",
            " [ 1.6350964   0.3484143  -0.29471496 -0.8506537 ]\n",
            " [ 0.7655658  -0.18303037  1.6271026  -0.6208647 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3. Create a Gaussian Matrix C with dimension 2X2, where values are drawn from normal distribution with a mean of 3 and a standard deviation of 0.5, using Tensorflow's random.normal function Display values of matrix C.\n",
        "---"
      ],
      "metadata": {
        "id": "lV9-6_EHv4aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the dimensions of the matrix\n",
        "matrix_shape = (2, 2)\n",
        "\n",
        "# Generate a Gaussian matrix using normal distribution\n",
        "mean = 3.0\n",
        "stddev = 0.5\n",
        "C = tf.random.normal(shape=matrix_shape, mean=mean, stddev=stddev)\n",
        "\n",
        "# Display the generated matrix\n",
        "print(\"Matrix C:\")\n",
        "print(C.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzZ9jBvPv92n",
        "outputId": "31358f2c-62d3-4914-85e0-9378c96f2a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix C:\n",
            "[[3.6540046 3.1320784]\n",
            " [3.3171096 2.8479006]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q4. Perform matrix addition between matrix A and matrix B and store the results in matrix D"
      ],
      "metadata": {
        "id": "OWlpZaadwA1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Matrix A has shape (3,3) while matrix B has shape(4,4) it is not possible to add these matrices as shapes are different\n",
        "Below is alternate example to show matrix addition"
      ],
      "metadata": {
        "id": "ashGC6HYwNix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix1 = tf.random.normal(shape=(2,2))\n",
        "matrix2 = tf.random.normal(shape=(2,2))\n",
        "D = tf.add(matrix1, matrix2)\n",
        "print(f'Matrix 1 :\\n {matrix1.numpy()}')\n",
        "print(f'\\nMatrix 2 :\\n {matrix2.numpy()}')\n",
        "print(f'\\nMatrix D :\\n {D.numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaLfBGAFwJfu",
        "outputId": "9096b688-1ede-44c5-cfef-87dc3e8d6e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix 1 :\n",
            " [[-0.6932158   0.05426229]\n",
            " [ 0.35234645 -0.10536154]]\n",
            "\n",
            "Matrix 2 :\n",
            " [[-0.37355402 -0.44618416]\n",
            " [-0.6125312   1.0581025 ]]\n",
            "\n",
            "Matrix D :\n",
            " [[-1.0667698  -0.39192188]\n",
            " [-0.26018474  0.95274097]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q5. Perform matrix multiplication between  matrix C and matrix D and store result in matrix E\n",
        "---"
      ],
      "metadata": {
        "id": "WHPsDZkBwMqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E = tf.matmul(C,D)\n",
        "\n",
        "print(f'Matrix C :\\n{C.numpy()}')\n",
        "print(f'\\nMatrix D :\\n{D.numpy()}')\n",
        "print(f'\\nMatrix E = CxD:\\n{E.numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7kdKKtpwRNL",
        "outputId": "8338651b-6b5c-44c9-a7e4-3acc252edf62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix C :\n",
            "[[3.6540046 3.1320784]\n",
            " [3.3171096 2.8479006]]\n",
            "\n",
            "Matrix D :\n",
            "[[-1.0667698  -0.39192188]\n",
            " [-0.26018474  0.95274097]]\n",
            "\n",
            "Matrix E = CxD:\n",
            "[[-4.712901   1.551975 ]\n",
            " [-4.2795725  1.4132638]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Performing additional matrix operations\n",
        "---"
      ],
      "metadata": {
        "id": "fv1K3Dj4wYzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Q1. Create a matrix F with dimensions 3x3, initialized random values using Tensorflows random_uniform function.\n",
        "---"
      ],
      "metadata": {
        "id": "k9IlCxLjweSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a matrix F\n",
        "F = tf.random.uniform(shape=(3,3))\n",
        "print(f'Matrix F :\\n{F.numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhoL2albwhAM",
        "outputId": "1457e7ec-27e1-4de6-ef75-c77b1efea030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix F :\n",
            "[[0.20843422 0.5754608  0.9162878 ]\n",
            " [0.53719544 0.5443474  0.21407783]\n",
            " [0.14513743 0.10453808 0.21670055]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q2. Calculate Transpose of Matrix F and store in Matrix G\n",
        "---"
      ],
      "metadata": {
        "id": "EczeEJINwnjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose the F matrix\n",
        "G = tf.transpose(F)\n",
        "\n",
        "# Print the matrix\n",
        "print(f'Matrix G :\\n{G.numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6uXkT94wqzy",
        "outputId": "eab2d642-da38-45db-e10d-4473851fd4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix G :\n",
            "[[0.20843422 0.53719544 0.14513743]\n",
            " [0.5754608  0.5443474  0.10453808]\n",
            " [0.9162878  0.21407783 0.21670055]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q3. Calculate element wise exponential of Matrix F and store the result in matrix H\n",
        "---"
      ],
      "metadata": {
        "id": "7N7casG-wtQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Element wise exponent\n",
        "H = tf.math.exp(F)\n",
        "\n",
        "# Print matrix H\n",
        "print(f'Matrix H :\\n{H.numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Ix9td4wwCL",
        "outputId": "4b15e0dc-b940-4b29-cece-da47c95ef6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix H :\n",
            "[[1.2317479 1.7779496 2.4999926]\n",
            " [1.711201  1.7234833 1.2387191]\n",
            " [1.1561985 1.1101977 1.2419721]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q4. Create a matrix I by concatenating Matrix F and matrix G horizontally\n",
        "---"
      ],
      "metadata": {
        "id": "ujJXtZz_wym4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate matrices F and G horizontally to create matrix I\n",
        "I = tf.concat([F, G], axis=1)\n",
        "\n",
        "# Display the original matrices and the concatenated matrix\n",
        "print(\"Matrix F:\")\n",
        "print(F.numpy())\n",
        "\n",
        "print(\"\\nMatrix G:\")\n",
        "print(G.numpy())\n",
        "\n",
        "print(\"\\nMatrix I (Concatenated Horizontally):\")\n",
        "print(I.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkmnP9Fjw2Ec",
        "outputId": "a0a5c246-7d61-4ab3-bad5-e31cd7ba7250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix F:\n",
            "[[0.20843422 0.5754608  0.9162878 ]\n",
            " [0.53719544 0.5443474  0.21407783]\n",
            " [0.14513743 0.10453808 0.21670055]]\n",
            "\n",
            "Matrix G:\n",
            "[[0.20843422 0.53719544 0.14513743]\n",
            " [0.5754608  0.5443474  0.10453808]\n",
            " [0.9162878  0.21407783 0.21670055]]\n",
            "\n",
            "Matrix I (Concatenated Horizontally):\n",
            "[[0.20843422 0.5754608  0.9162878  0.20843422 0.53719544 0.14513743]\n",
            " [0.53719544 0.5443474  0.21407783 0.5754608  0.5443474  0.10453808]\n",
            " [0.14513743 0.10453808 0.21670055 0.9162878  0.21407783 0.21670055]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Q5. Create a matrix J by concatenating matrix F and matrix H vertically"
      ],
      "metadata": {
        "id": "8mEgIN7Rw6oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate matrices F and H vertically to create matrix J\n",
        "J = tf.concat([F, H], axis=0)\n",
        "\n",
        "# Display the original matrices and the concatenated matrix\n",
        "print(\"Matrix F:\")\n",
        "print(F.numpy())\n",
        "\n",
        "print(\"\\nMatrix H:\")\n",
        "print(H.numpy())\n",
        "\n",
        "print(\"\\nMatrix J (Concatenated Vertically):\")\n",
        "print(J.numpy())"
      ],
      "metadata": {
        "id": "HYtfSpnhxL6q",
        "outputId": "ba09f7fb-999c-445d-9123-4a03da03cf55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix F:\n",
            "[[0.20843422 0.5754608  0.9162878 ]\n",
            " [0.53719544 0.5443474  0.21407783]\n",
            " [0.14513743 0.10453808 0.21670055]]\n",
            "\n",
            "Matrix H:\n",
            "[[1.2317479 1.7779496 2.4999926]\n",
            " [1.711201  1.7234833 1.2387191]\n",
            " [1.1561985 1.1101977 1.2419721]]\n",
            "\n",
            "Matrix J (Concatenated Vertically):\n",
            "[[0.20843422 0.5754608  0.9162878 ]\n",
            " [0.53719544 0.5443474  0.21407783]\n",
            " [0.14513743 0.10453808 0.21670055]\n",
            " [1.2317479  1.7779496  2.4999926 ]\n",
            " [1.711201   1.7234833  1.2387191 ]\n",
            " [1.1561985  1.1101977  1.2419721 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aU2TAfgzxPiJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}